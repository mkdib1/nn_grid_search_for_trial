{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7GziC-amean"
      },
      "source": [
        "# LIBRARIES & PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVaQ2EuhCUs6"
      },
      "outputs": [],
      "source": [
        "# !pip install scikeras\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# from google.colab import drive\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout, BatchNormalization, Reshape, Lambda, Input, Activation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7o-kWEcpikB"
      },
      "outputs": [],
      "source": [
        "# Setting seeds\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN2zC6DpCfkF",
        "outputId": "0644e6f0-4c3c-41b0-d5c7-b565aad2295e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mounting gdrive folder\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bji49at9mmoX"
      },
      "source": [
        "# FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ2JScuH97Kl"
      },
      "outputs": [],
      "source": [
        "def gaussian_noise(signal, sigma):\n",
        "    noise = np.random.normal(0, sigma, signal.shape)\n",
        "    return signal + noise\n",
        "\n",
        "def time_reverse(signal, p_aug_rev):\n",
        "    if np.random.rand() < p_aug_rev:\n",
        "        return np.flip(signal) # reverse the order of elements in an array passed as param\n",
        "    else:\n",
        "        return signal\n",
        "\n",
        "def sign_flip(signal, p_aug_flip):\n",
        "    if np.random.rand() < p_aug_flip:\n",
        "        return -signal  # flipping the sign\n",
        "    else:\n",
        "        return signal\n",
        "\n",
        "def data_augmented(signal, sigma, p_aug_rev, p_aug_flip):\n",
        "    signal = gaussian_noise(signal, sigma)\n",
        "    signal = time_reverse(signal, p_aug_rev)\n",
        "    signal = sign_flip(signal, p_aug_flip)\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NlgomarYwXz"
      },
      "outputs": [],
      "source": [
        "def compile_model(model):\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                                   loss='categorical_crossentropy',\n",
        "                                   metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnObNyeXEz8q"
      },
      "outputs": [],
      "source": [
        "# In order to save computational time, we set epochs=30 and patience=3 differently from the original net training\n",
        "\n",
        "def train_model(model, X_train, y_train, X_test, y_test, epochs=30, batch_size=32):\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=False)\n",
        "    callbacks = [early_stopping]\n",
        "\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=callbacks,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n81E6pfaFkHg"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f'Test accuracy: {accuracy:.4f}')\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-QvvsPp1oUw"
      },
      "source": [
        "# DATASET LOADING & VARIABLES SETTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLLYZvMG1qoL"
      },
      "outputs": [],
      "source": [
        "# loading dataset\n",
        "eeg = pd.read_csv('/content/gdrive/MyDrive/eeg.csv', sep=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA_Pf1OoUqmM"
      },
      "outputs": [],
      "source": [
        "X = eeg.drop(columns=['class'])\n",
        "y = eeg['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train_plt = y_train.copy()\n",
        "y_test_plt = y_test.copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqKQYMkfjJOd"
      },
      "source": [
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC6_3EOi_jbJ"
      },
      "source": [
        "# Hyperparameters tuning for Augmented data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYX8QCcn7fEc"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "  inputs = Input(shape=(X_train.shape[1], 1))\n",
        "\n",
        "  x = Conv1D(filters=1024, kernel_size=4, strides=2, padding='same')(inputs)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D(pool_size=2)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Conv1D(filters=512, kernel_size=4, strides=2, padding='same')(inputs)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D(pool_size=2)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Conv1D(filters=256, kernel_size=4, strides=2, padding='same')(inputs)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D(pool_size=2)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Conv1D(filters=128, kernel_size=4, strides=2, padding='same')(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D(pool_size=2)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(128)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = Reshape((1, 128))(x)\n",
        "\n",
        "  x = LSTM(128, return_sequences=True, recurrent_dropout=0.2)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = LSTM(64, return_sequences=True, recurrent_dropout=0.2)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  x = LSTM(32, return_sequences=False, recurrent_dropout=0.2)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "  outputs = Dense(5, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daWJqdJk7hm5"
      },
      "outputs": [],
      "source": [
        "# defining 3*3 matrix of values which will be used for grid search tuning\n",
        "sigma_values = [0.01, 0.05, 0.1]\n",
        "p_aug_rev_values = [0, 0.2, 0.5, 0.8]\n",
        "p_aug_flip_values = [0, 0.2, 0.5, 0.8]\n",
        "\n",
        "param_grid = list(itertools.product(sigma_values, p_aug_rev_values, p_aug_flip_values))\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "results = []\n",
        "\n",
        "# count = 27\n",
        "for sigma, p_aug_rev, p_aug_flip in param_grid:\n",
        "    X_train_augm = np.apply_along_axis(lambda row: data_augmented(row, sigma, p_aug_rev, p_aug_flip), axis=1, arr=X_train)\n",
        "    model_hna = create_model()\n",
        "    compile_model(model_hna)\n",
        "    history_hna = train_model(model_hna, X_train_augm, y_train, X_test, y_test)\n",
        "    _, acc = evaluate_model(model_hna, X_test, y_test)\n",
        "    results.append((sigma, p_aug_rev, p_aug_flip, acc))\n",
        "    # count -= 1\n",
        "    # print(f\"Mancano {count} addestramenti\")\n",
        "\n",
        "    if acc  > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_params = (sigma, p_aug_rev, p_aug_flip)\n",
        "\n",
        "print(\"Best parameters:\")\n",
        "print(\"Sigma:\", best_params[0])\n",
        "print(\"Time Reverse Probability:\", best_params[1])\n",
        "print(\"Sign Flip Probability:\", best_params[2])\n",
        "print(\"Best Accuracy:\", best_accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}